# Improving Event Detection via Open-domain Trigger Knowledge
### Motivation
The long tail issue in Event Detection: 78.2% trigger words with frequency less than 5.

![image-20201130155625612](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130155625612.png)

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130161849299.png" alt="image-20201130161849299" style="zoom:80%;" />



Trigger words in sentences can be divided into Densely, Sparsely and Unseen labels. Previous semi-supervised and distantly-supervised methods can't solve this problem well.

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130160813289.png" alt="image-20201130160813289" style="zoom:80%;" />

### Contribution

- To the best of our knowledge, we are the first to leverage the wealth of the open-domain
  trigger knowledge to improve ED.
- We propose a novel teacher-student model (EKD) that can learn from both labeled and
  unlabeled data, so as to improve ED performance by reducing the in-built biases in annotations.
- Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines
  which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities.

### Methodology

#### Architecture

![image-20201130162932217](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130162932217.png)

#### Knowledge enrichment（Wordnet）

**Hypothesis:** The word sense in wordnet contains information about whether it is a trigger。

- Step 1: Disambiguate all words in the target sentence and convert them to the wordnet standard  word sense. (*Using nltk package*)
- Step 2: Determine whether word sense is trigger. (Using a dictionary lookup in *Open-Domain Event Detection using Distant Supervision*)

![image-20201130162823593](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130162823593.png)

Using New York Times corpus as unlabeled data, get 733,848 annotated sentences :

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130163318096.png" alt="image-20201130163318096" style="zoom:67%;" />

After knowledge enrichment, one sentence is derived into three sentences:

- Raw sentence: $S=\{w_1, w_2, ..., w_i, ...,w_n\}$;
- Knowledge-attending Sentences: $S^+=\{w_1, w_2, ..., B-TRI, w_i, E-TRI, ...,w_n\}$;
- Knowledge-absent Sentences: $S^-=\{w_1, w_2, ..., [MASK], ...,w_n\}$.

The `B-TRI`&`E-TRI` tokens are paper-defined and using BERT MLM task to get their embeddings.

#### Event prediction

Using **bert-encoder** as feature representation, using a **full-connected layer** as classification layer.

- Output: `O`, $O_{ijc}$: The logistical value of the `j-th` word in the `i-th` sentence being `c-th` type of trigger;
- Loss: 
  - $p\left(Y_{(i)} \mid S_{(i)}, \theta\right)=\sum_{j=1}^{n} \frac{\exp \left(O_{i j c}\right)}{\sum_{c=1}^{C} \exp \left(O_{i j c}\right)} / n$
  - $J_{L}(\theta)=-\sum_{i=1}^{N_{L}} \log p\left(Y_{(i)} \mid S_{(i)}, \theta\right)$

#### Knowledge distillation





### Experiments
### Codes
### Discussion