# Improving Event Detection via Open-domain Trigger Knowledge
### Motivation
The long tail issue in Event Detection: 78.2% trigger words with frequency less than 5.

![image-20201130155625612](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130155625612.png)

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130161849299.png" alt="image-20201130161849299" style="zoom:80%;" />



Trigger words in sentences can be divided into Densely, Sparsely and Unseen labels. Previous semi-supervised and distantly-supervised methods can't solve this problem well.

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130160813289.png" alt="image-20201130160813289" style="zoom:80%;" />

### Contribution

- To the best of our knowledge, we are the first to leverage the wealth of the open-domain
  trigger knowledge to improve ED.
- We propose a novel teacher-student model (EKD) that can learn from both labeled and
  unlabeled data, so as to improve ED performance by reducing the in-built biases in annotations.
- Experiments on benchmark ACE2005 show that our method surpasses nine strong baselines
  which are also enhanced with knowledge. Detailed studies show that our method can be conveniently adapted to distill other knowledge, such as entities.

### Methodology

#### Architecture

![image-20201130162932217](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130162932217.png)

#### Knowledge enrichment（Wordnet）

**Hypothesis:** The word sense in wordnet contains information about whether it is a trigger。

- Step 1: Disambiguate all words in the target sentence and convert them to the wordnet standard  word sense. (*Using nltk package*)
- Step 2: Determine whether word sense is trigger. (Using a dictionary lookup in *Open-Domain Event Detection using Distant Supervision*)

![image-20201130162823593](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130162823593.png)

Using New York Times corpus as unlabeled data, get 733,848 annotated sentences :

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201130163318096.png" alt="image-20201130163318096" style="zoom:67%;" />

After knowledge enrichment, one sentence is derived into three sentences:

- Raw sentence: $S=\{w_1, w_2, ..., w_i, ...,w_n\}$;
- Knowledge-attending Sentences: $S^+=\{w_1, w_2, ..., B-TRI, w_i, E-TRI, ...,w_n\}$;
- Knowledge-absent Sentences: $S^-=\{w_1, w_2, ..., [MASK], ...,w_n\}$;

The `B-TRI`&`E-TRI` tokens are paper-defined and using BERT MLM task to get their embeddings.

#### Event prediction

Using **bert-encoder** as feature representation, using a **full-connected layer** as classification layer.

- Output: `O`, $O_{ijc}$: The logistical value of the `j-th` word in the `i-th` sentence being `c-th` type of trigger;
- Loss: 
  - $p\left(Y_{(i)} \mid S_{(i)}, \theta\right)=\sum_{j=1}^{n} \frac{\exp \left(O_{i j c}\right)}{\sum_{c=1}^{C} \exp \left(O_{i j c}\right)} / n$;
  - $J_{L}(\theta)=-\sum_{i=1}^{N_{L}} \log p\left(Y_{(i)} \mid S_{(i)}, \theta\right)$.

#### Knowledge distillation

- Using a **teacher model** and a **student model**, which share the **same parameters**;

- Feed teacher model with $S^+$ while feed student model with $S^-$;

- Using `KL-divergence` on  teacher and student models :
  $$
  \begin{aligned} J_{T}(\theta) &=\mathbf{K L}\left(p\left(Y \mid S^{+}, \theta\right) \| p\left(Y \mid S^{-}, \theta\right)\right) \\ &=\sum_{k=1}^{N_{L}+N_{U}} p\left(Y_{(k)} \mid S_{(k)}^{+}, \theta\right) \frac{p\left(Y_{(k)} \mid S_{(k)}^{+}, \theta\right)}{p\left(Y_{(k)} \mid S_{(k)}^{-}, \theta\right)} \end{aligned}
  $$
  

- Train model **jointly** by: $J(\theta)=J_{L}(\theta)+\lambda * J_{T}(\theta)$.

### Experiments

#### Experiment setting

- Datasets：
  - ACE2005 contains **13,672 labeled sentences** distributed in **599 articles**；
  - unlabeled data： **40,236**;

- Evaluation: **Precision, Recall** and **micro-averaged F1 scores** in the form of percentage over all **33 events**；

- Hyperparameters：
  - BERT ：**24 16-head attention layers** and **1024 hidden embedding dimension**；
  - batch size：**32**；
  - maximum sequence length： **128**；
  - λ：1；

- learning rate: **3e-5**;

- best result: around **12,500 epochs**

#### Overall performance

 <img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201201003840303.png" alt="image-20201201003840303" style="zoom:80%;" />

#### Test without trigger knowledge

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201201004113413.png" alt="image-20201201004113413" style="zoom: 67%;" />

The model has already learned the open-domain trigger knowledge and don't need to tag trigger in the test data.

#### Domain Adaption & Various Labeling Frequencies

![image-20201201004332880](3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201201004332880.png)

#### Knowledge-Agnostic

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201201004408250.png" alt="image-20201201004408250" style="zoom:50%;" /> 

The architecture can also learn open-domain knowledge of entity, syntactic and argument. 

### Codes

<https://github.com/shuaiwa16/ekd>

Modified from [Google/uda]([google-research/uda: Unsupervised Data Augmentation (UDA) (github.com)](https://github.com/google-research/uda)) 

<img src="3.%20Improving%20Event%20Detection%20via%20Open-domain%20Trigger%20Knowledge.assets/image-20201201005349025.png" alt="image-20201201005349025" style="zoom: 67%;" />



### Discussion

#### Advantage

- Combines distant-supervised (wordnet) and semi-supervised (EKD)
- Data enhancement method

#### Disadvantage

- Did not do ablation analysis
- The experiment of module versatility has no details
- The code is incomplete and the authenticity is questionable